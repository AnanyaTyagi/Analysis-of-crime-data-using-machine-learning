{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPKDMPkFRl5NcbhZV+dKK71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnanyaTyagi/Analysis-of-crime-data-using-machine-learning/blob/master/Graph_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDoeC4_05lcq"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# EVALUATE ALL CHECKPOINTS AND PLOT FID/IS vs EPOCHS (FIXED)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import math\n",
        "\n",
        "# Try to mount drive, but continue if it fails\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive/MyDrive'):\n",
        "        drive.mount('/content/drive')\n",
        "    print(\"✅ Drive mounted\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Drive mount failed or not in Colab: {e}\")\n",
        "    print(\"Make sure to update the paths below to your actual checkpoint locations\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# PATHS - UPDATE THESE TO YOUR ACTUAL DIRECTORIES\n",
        "# -------------------------\n",
        "\n",
        "# For Diffusion\n",
        "DIFFUSION_DIR = \"/content/drive/MyDrive/diffusion_cifar10_runs\"\n",
        "DIFFUSION_CKPT_PATTERN = \"diffusion_epoch_*.pth\"\n",
        "\n",
        "# Output directory for graphs\n",
        "GRAPH_OUTPUT_DIR = \"/content/drive/MyDrive/model_evaluation_graphs\"\n",
        "os.makedirs(GRAPH_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Checkpoint directory: {DIFFUSION_DIR}\")\n",
        "print(f\"Graphs will be saved to: {GRAPH_OUTPUT_DIR}\")\n",
        "\n",
        "# Verify directory exists\n",
        "if not os.path.exists(DIFFUSION_DIR):\n",
        "    print(f\"❌ ERROR: Directory does not exist: {DIFFUSION_DIR}\")\n",
        "    print(\"Please update DIFFUSION_DIR to the correct path\")\n",
        "else:\n",
        "    print(f\"✅ Checkpoint directory found\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# MODEL DEFINITIONS (same as training)\n",
        "# -------------------------\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, t):\n",
        "        device_ = t.device\n",
        "        half = self.dim // 2\n",
        "        emb_factor = math.log(10000) / (half - 1)\n",
        "        emb = torch.exp(torch.arange(half, device=device_) * -emb_factor)\n",
        "        emb = t[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        return emb\n",
        "\n",
        "def get_num_groups(channels):\n",
        "    if channels >= 32:\n",
        "        num_groups = 8\n",
        "    elif channels >= 16:\n",
        "        num_groups = 4\n",
        "    elif channels >= 8:\n",
        "        num_groups = 2\n",
        "    else:\n",
        "        num_groups = 1\n",
        "    while channels % num_groups != 0:\n",
        "        num_groups -= 1\n",
        "    return max(1, num_groups)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, channels, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.num_heads = num_heads\n",
        "        while channels % num_heads != 0 and num_heads > 1:\n",
        "            num_heads -= 1\n",
        "        self.num_heads = num_heads\n",
        "        self.norm = nn.GroupNorm(get_num_groups(channels), channels)\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, 1)\n",
        "        self.proj = nn.Conv2d(channels, channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        qkv = self.qkv(self.norm(x))\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "        q = q.view(B, self.num_heads, C // self.num_heads, H * W)\n",
        "        k = k.view(B, self.num_heads, C // self.num_heads, H * W)\n",
        "        v = v.view(B, self.num_heads, C // self.num_heads, H * W)\n",
        "        scale = (C // self.num_heads) ** -0.5\n",
        "        attn = torch.softmax(torch.einsum('bhcn,bhcm->bhnm', q, k) * scale, dim=-1)\n",
        "        out = torch.einsum('bhnm,bhcm->bhcn', attn, v)\n",
        "        out = out.reshape(B, C, H, W)\n",
        "        return x + self.proj(out)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(time_dim, out_ch))\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(get_num_groups(in_ch), in_ch),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(get_num_groups(out_ch), out_ch),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "        )\n",
        "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        h = self.block1(x)\n",
        "        t = self.time_mlp(t_emb)[:, :, None, None]\n",
        "        h = h + t\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, img_ch=3, base_channels=128, time_dim=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPosEmb(time_dim),\n",
        "            nn.Linear(time_dim, time_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_dim * 4, time_dim),\n",
        "        )\n",
        "        ch1 = base_channels\n",
        "        ch2 = base_channels * 2\n",
        "        ch3 = base_channels * 4\n",
        "\n",
        "        self.down1 = nn.ModuleList([ResBlock(img_ch, ch1, time_dim, dropout), ResBlock(ch1, ch1, time_dim, dropout)])\n",
        "        self.down2 = nn.ModuleList([ResBlock(ch1, ch2, time_dim, dropout), ResBlock(ch2, ch2, time_dim, dropout)])\n",
        "        self.attn2 = SelfAttention(ch2, num_heads=4)\n",
        "        self.down3 = nn.ModuleList([ResBlock(ch2, ch3, time_dim, dropout), ResBlock(ch3, ch3, time_dim, dropout)])\n",
        "        self.attn3 = SelfAttention(ch3, num_heads=4)\n",
        "        self.pool = nn.AvgPool2d(2)\n",
        "\n",
        "        self.mid1 = ResBlock(ch3, ch3, time_dim, dropout)\n",
        "        self.mid_attn = SelfAttention(ch3, num_heads=4)\n",
        "        self.mid2 = ResBlock(ch3, ch3, time_dim, dropout)\n",
        "\n",
        "        self.up2 = nn.ModuleList([ResBlock(ch3 + ch2, ch2, time_dim, dropout), ResBlock(ch2, ch2, time_dim, dropout)])\n",
        "        self.attn_up2 = SelfAttention(ch2, num_heads=4)\n",
        "        self.up1 = nn.ModuleList([ResBlock(ch2 + ch1, ch1, time_dim, dropout), ResBlock(ch1, ch1, time_dim, dropout)])\n",
        "        self.attn_up1 = SelfAttention(ch1, num_heads=4)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.GroupNorm(get_num_groups(ch1), ch1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(ch1, img_ch, 3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t_emb = self.time_mlp(t)\n",
        "        h = x\n",
        "        for block in self.down1:\n",
        "            h = block(h, t_emb)\n",
        "        d1 = h\n",
        "        h = self.pool(h)\n",
        "        for block in self.down2:\n",
        "            h = block(h, t_emb)\n",
        "        h = self.attn2(h)\n",
        "        d2 = h\n",
        "        h = self.pool(h)\n",
        "        for block in self.down3:\n",
        "            h = block(h, t_emb)\n",
        "        h = self.attn3(h)\n",
        "        h = self.mid1(h, t_emb)\n",
        "        h = self.mid_attn(h)\n",
        "        h = self.mid2(h, t_emb)\n",
        "        h = self.upsample(h)\n",
        "        h = torch.cat([h, d2], dim=1)\n",
        "        for block in self.up2:\n",
        "            h = block(h, t_emb)\n",
        "        h = self.attn_up2(h)\n",
        "        h = self.upsample(h)\n",
        "        h = torch.cat([h, d1], dim=1)\n",
        "        for block in self.up1:\n",
        "            h = block(h, t_emb)\n",
        "        h = self.attn_up1(h)\n",
        "        return self.final(h)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# DIFFUSION SAMPLING\n",
        "# -------------------------\n",
        "\n",
        "T = 1000\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0.0001, 0.9999)\n",
        "\n",
        "betas = cosine_beta_schedule(T)\n",
        "alphas = 1.0 - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "alphas_cumprod_prev = torch.cat([torch.tensor([1.0], dtype=torch.float32), alphas_cumprod[:-1]], dim=0)\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "betas = betas.to(device)\n",
        "alphas = alphas.to(device)\n",
        "sqrt_one_minus_alphas_cumprod = sqrt_one_minus_alphas_cumprod.to(device)\n",
        "sqrt_recip_alphas = sqrt_recip_alphas.to(device)\n",
        "posterior_variance = posterior_variance.to(device)\n",
        "\n",
        "def denorm(x):\n",
        "    return (x.clamp(-1,1) + 1)/2\n",
        "\n",
        "def p_sample(model, x, t_index: int):\n",
        "    b = x.size(0)\n",
        "    t = torch.full((b,), t_index, device=device, dtype=torch.long)\n",
        "    eps_theta = model(x, t)\n",
        "    beta_t = betas[t_index]\n",
        "    sqrt_one_minus_alpha_bar_t = sqrt_one_minus_alphas_cumprod[t_index]\n",
        "    sqrt_recip_alpha_t = sqrt_recip_alphas[t_index]\n",
        "    model_mean = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alpha_bar_t * eps_theta)\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x)\n",
        "        var = posterior_variance[t_index]\n",
        "        return model_mean + torch.sqrt(var) * noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model, shape):\n",
        "    model.eval()\n",
        "    img = torch.randn(shape, device=device)\n",
        "    for t_index in reversed(range(T)):\n",
        "        img = p_sample(model, img, t_index)\n",
        "    return img\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EVALUATION FUNCTIONS\n",
        "# -------------------------\n",
        "\n",
        "def load_model_from_checkpoint(ckpt_path):\n",
        "    \"\"\"Load model from checkpoint with proper EMA handling\"\"\"\n",
        "\n",
        "    # Load checkpoint\n",
        "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Create model\n",
        "    model = UNet(img_ch=3, base_channels=128, time_dim=256, dropout=0.1).to(device)\n",
        "\n",
        "    # Try to get the right state dict\n",
        "    if 'ema' in ckpt:\n",
        "        state_dict = ckpt['ema']\n",
        "    elif 'model' in ckpt:\n",
        "        state_dict = ckpt['model']\n",
        "    else:\n",
        "        state_dict = ckpt\n",
        "\n",
        "    # Load with strict=False to handle any mismatches\n",
        "    try:\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Loading with strict=False due to: {e}\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def generate_samples_from_checkpoint(ckpt_path, output_dir, num_samples=5000):\n",
        "    \"\"\"Generate samples from a checkpoint and save to directory\"\"\"\n",
        "    print(f\"\\nGenerating samples from: {os.path.basename(ckpt_path)}\")\n",
        "\n",
        "    model = load_model_from_checkpoint(ckpt_path)\n",
        "    model.eval()\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    bs = 100\n",
        "    saved = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(total=num_samples, desc=\"Generating\")\n",
        "        while saved < num_samples:\n",
        "            cur = min(bs, num_samples - saved)\n",
        "            samples = p_sample_loop(model, (cur, 3, 32, 32))\n",
        "            samples = denorm(samples).cpu()\n",
        "\n",
        "            for i in range(cur):\n",
        "                save_image(samples[i], os.path.join(output_dir, f\"{saved + i:05d}.png\"))\n",
        "\n",
        "            saved += cur\n",
        "            pbar.update(cur)\n",
        "        pbar.close()\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "\n",
        "def calculate_metrics_for_samples(samples_dir):\n",
        "    \"\"\"Calculate FID and IS for generated samples\"\"\"\n",
        "    print(f\"Calculating metrics for: {samples_dir}\")\n",
        "\n",
        "    try:\n",
        "        from torch_fidelity import calculate_metrics\n",
        "    except:\n",
        "        import subprocess\n",
        "        subprocess.check_call(['pip', 'install', '-q', 'torch-fidelity>=0.3.0'])\n",
        "        from torch_fidelity import calculate_metrics\n",
        "\n",
        "    orig_torch_load = torch.load\n",
        "    def _compat_load(*args, **kwargs):\n",
        "        kwargs.setdefault(\"weights_only\", False)\n",
        "        return orig_torch_load(*args, **kwargs)\n",
        "    torch.load = _compat_load\n",
        "\n",
        "    try:\n",
        "        metrics_fid = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            input2=\"cifar10-train\",\n",
        "            fid=True,\n",
        "            kid=False,\n",
        "            isc=False,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        metrics_is = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            fid=False,\n",
        "            kid=False,\n",
        "            isc=True,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "    finally:\n",
        "        torch.load = orig_torch_load\n",
        "\n",
        "    fid = metrics_fid.get(\"frechet_inception_distance\", None)\n",
        "    is_mean = (metrics_is.get(\"inception_score_mean\") or\n",
        "               metrics_is.get(\"isc_mean\") or\n",
        "               metrics_is.get(\"inception_score\"))\n",
        "    is_std = metrics_is.get(\"inception_score_std\", metrics_is.get(\"isc_std\", None))\n",
        "\n",
        "    return fid, is_mean, is_std\n",
        "\n",
        "\n",
        "def evaluate_all_checkpoints(model_dir, ckpt_pattern, temp_sample_dir, num_samples=5000,\n",
        "                             select_epochs=None):\n",
        "    \"\"\"Evaluate all checkpoints in a directory\"\"\"\n",
        "\n",
        "    ckpt_files = sorted(glob.glob(os.path.join(model_dir, ckpt_pattern)))\n",
        "\n",
        "    if not ckpt_files:\n",
        "        print(f\"❌ No checkpoints found matching pattern: {ckpt_pattern} in {model_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"Found {len(ckpt_files)} checkpoints\")\n",
        "\n",
        "    epochs = []\n",
        "    for f in ckpt_files:\n",
        "        match = re.search(r'epoch[_-](\\d+)', os.path.basename(f))\n",
        "        if match:\n",
        "            epochs.append(int(match.group(1)))\n",
        "\n",
        "    if not epochs:\n",
        "        print(\"❌ Could not extract epoch numbers from checkpoint filenames\")\n",
        "        return None, None, None\n",
        "\n",
        "    sorted_pairs = sorted(zip(epochs, ckpt_files))\n",
        "    epochs, ckpt_files = zip(*sorted_pairs)\n",
        "\n",
        "    if select_epochs is not None:\n",
        "        filtered_pairs = [(e, f) for e, f in zip(epochs, ckpt_files) if e in select_epochs]\n",
        "        if filtered_pairs:\n",
        "            epochs, ckpt_files = zip(*filtered_pairs)\n",
        "            print(f\"Evaluating {len(epochs)} selected checkpoints: {list(epochs)}\")\n",
        "        else:\n",
        "            print(f\"❌ No checkpoints found for selected epochs: {select_epochs}\")\n",
        "            return None, None, None\n",
        "\n",
        "    fids = []\n",
        "    is_means = []\n",
        "    is_stds = []\n",
        "\n",
        "    for epoch, ckpt_path in zip(epochs, ckpt_files):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating Epoch {epoch}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            sample_output_dir = os.path.join(temp_sample_dir, f\"epoch_{epoch}\")\n",
        "            generate_samples_from_checkpoint(ckpt_path, sample_output_dir, num_samples)\n",
        "\n",
        "            fid, is_mean, is_std = calculate_metrics_for_samples(sample_output_dir)\n",
        "\n",
        "            fids.append(fid)\n",
        "            is_means.append(is_mean)\n",
        "            is_stds.append(is_std if is_std is not None else 0)\n",
        "\n",
        "            # FIXED: Properly format the is_std value\n",
        "            is_std_str = f\"{is_std:.2f}\" if is_std else \"0.00\"\n",
        "            print(f\"✅ Epoch {epoch}: FID={fid:.2f}, IS={is_mean:.2f}±{is_std_str}\")\n",
        "\n",
        "            import shutil\n",
        "            shutil.rmtree(sample_output_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error evaluating epoch {epoch}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return list(epochs), fids, is_means\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# MAIN EVALUATION\n",
        "# -------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING DIFFUSION MODEL CHECKPOINTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "TEMP_SAMPLE_DIR = \"/content/temp_eval_samples\"\n",
        "os.makedirs(TEMP_SAMPLE_DIR, exist_ok=True)\n",
        "\n",
        "# SELECT WHICH EPOCHS TO EVALUATE\n",
        "select_epochs = list(range(50, 501, 50))  # [50, 100, 150, ..., 500]\n",
        "print(f\"Will evaluate epochs: {select_epochs}\")\n",
        "\n",
        "diffusion_epochs, diffusion_fids, diffusion_is = evaluate_all_checkpoints(\n",
        "    DIFFUSION_DIR,\n",
        "    DIFFUSION_CKPT_PATTERN,\n",
        "    os.path.join(TEMP_SAMPLE_DIR, \"diffusion\"),\n",
        "    num_samples=5000,\n",
        "    select_epochs=select_epochs\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PLOT RESULTS\n",
        "# -------------------------\n",
        "\n",
        "if diffusion_epochs is not None and len(diffusion_epochs) > 0:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(diffusion_epochs, diffusion_fids, 'b-o', linewidth=2, markersize=8, label='Diffusion')\n",
        "    ax1.set_xlabel('Epoch', fontsize=14)\n",
        "    ax1.set_ylabel('FID (lower is better)', fontsize=14)\n",
        "    ax1.set_title('FID vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=12)\n",
        "\n",
        "    ax2.plot(diffusion_epochs, diffusion_is, 'r-o', linewidth=2, markersize=8, label='Diffusion')\n",
        "    ax2.set_xlabel('Epoch', fontsize=14)\n",
        "    ax2.set_ylabel('Inception Score (higher is better)', fontsize=14)\n",
        "    ax2.set_title('Inception Score vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(GRAPH_OUTPUT_DIR, 'diffusion_metrics_vs_epochs.png'), dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n✅ Graph saved to: {GRAPH_OUTPUT_DIR}/diffusion_metrics_vs_epochs.png\")\n",
        "    plt.show()\n",
        "\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        'Epoch': diffusion_epochs,\n",
        "        'FID': diffusion_fids,\n",
        "        'IS_mean': diffusion_is\n",
        "    })\n",
        "    df.to_csv(os.path.join(GRAPH_OUTPUT_DIR, 'diffusion_metrics.csv'), index=False)\n",
        "    print(f\"✅ Data saved to: {GRAPH_OUTPUT_DIR}/diffusion_metrics.csv\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    best_fid_idx = np.argmin(diffusion_fids)\n",
        "    best_is_idx = np.argmax(diffusion_is)\n",
        "    print(f\"Best FID: {diffusion_fids[best_fid_idx]:.2f} at epoch {diffusion_epochs[best_fid_idx]}\")\n",
        "    print(f\"Best IS: {diffusion_is[best_is_idx]:.2f} at epoch {diffusion_epochs[best_is_idx]}\")\n",
        "    print(f\"Final FID: {diffusion_fids[-1]:.2f} at epoch {diffusion_epochs[-1]}\")\n",
        "    print(f\"Final IS: {diffusion_is[-1]:.2f} at epoch {diffusion_epochs[-1]}\")\n",
        "else:\n",
        "    print(\"❌ No checkpoints were successfully evaluated\")\n",
        "\n",
        "print(\"\\n✅ Evaluation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# EVALUATE GAN CHECKPOINTS AND PLOT FID/IS vs EPOCHS\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import math\n",
        "\n",
        "# Try to mount drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive/MyDrive'):\n",
        "        drive.mount('/content/drive')\n",
        "    print(\"✅ Drive mounted\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Drive mount failed or not in Colab: {e}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# PATHS\n",
        "# -------------------------\n",
        "\n",
        "GAN_DIR = \"/content/drive/MyDrive/gan_cifar10_runs\"\n",
        "GAN_CKPT_PATTERN = \"dcgan_epoch_*.pth\"\n",
        "\n",
        "GRAPH_OUTPUT_DIR = \"/content/drive/MyDrive/model_evaluation_graphs\"\n",
        "os.makedirs(GRAPH_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Checkpoint directory: {GAN_DIR}\")\n",
        "print(f\"Graphs will be saved to: {GRAPH_OUTPUT_DIR}\")\n",
        "\n",
        "if not os.path.exists(GAN_DIR):\n",
        "    print(f\"❌ ERROR: Directory does not exist: {GAN_DIR}\")\n",
        "else:\n",
        "    print(f\"✅ Checkpoint directory found\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# GAN MODEL DEFINITIONS\n",
        "# -------------------------\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=128, fm=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # (N, latent_dim, 1, 1) -> (N, fm*8, 4, 4)\n",
        "            nn.ConvTranspose2d(latent_dim, fm*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(fm*8), nn.ReLU(True),\n",
        "\n",
        "            # 4->8\n",
        "            nn.ConvTranspose2d(fm*8, fm*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(fm*4), nn.ReLU(True),\n",
        "\n",
        "            # 8->16\n",
        "            nn.ConvTranspose2d(fm*4, fm*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(fm*2), nn.ReLU(True),\n",
        "\n",
        "            # 16->32\n",
        "            nn.ConvTranspose2d(fm*2, fm, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(fm), nn.ReLU(True),\n",
        "\n",
        "            # (N, fm, 32, 32) -> (N, 3, 32, 32)\n",
        "            nn.ConvTranspose2d(fm, 3, 3, 1, 1, bias=False),\n",
        "            nn.Tanh(),  # [-1,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "\n",
        "def denorm(x):\n",
        "    return (x.clamp(-1,1) + 1)/2\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EVALUATION FUNCTIONS\n",
        "# -------------------------\n",
        "\n",
        "def load_generator_from_checkpoint(ckpt_path, latent_dim=128, gen_fm=128):\n",
        "    \"\"\"Load generator from checkpoint\"\"\"\n",
        "    print(f\"\\nLoading generator from: {os.path.basename(ckpt_path)}\")\n",
        "\n",
        "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Get hyperparameters from checkpoint if available\n",
        "    latent_dim = ckpt.get('LATENT_DIM', latent_dim)\n",
        "    gen_fm = ckpt.get('GEN_FM', gen_fm)\n",
        "\n",
        "    # Create generator\n",
        "    G = Generator(latent_dim, gen_fm).to(device)\n",
        "\n",
        "    # Load state dict\n",
        "    if 'G' in ckpt:\n",
        "        G.load_state_dict(ckpt['G'])\n",
        "    elif 'generator' in ckpt:\n",
        "        G.load_state_dict(ckpt['generator'])\n",
        "    else:\n",
        "        G.load_state_dict(ckpt)\n",
        "\n",
        "    G.eval()\n",
        "    return G, latent_dim\n",
        "\n",
        "\n",
        "def generate_samples_from_gan(ckpt_path, output_dir, num_samples=5000):\n",
        "    \"\"\"Generate samples from a GAN checkpoint\"\"\"\n",
        "    print(f\"\\nGenerating samples from: {os.path.basename(ckpt_path)}\")\n",
        "\n",
        "    G, latent_dim = load_generator_from_checkpoint(ckpt_path)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    bs = 100\n",
        "    saved = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(total=num_samples, desc=\"Generating\")\n",
        "        while saved < num_samples:\n",
        "            cur = min(bs, num_samples - saved)\n",
        "\n",
        "            # Generate random latent vectors\n",
        "            z = torch.randn(cur, latent_dim, 1, 1, device=device)\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = G(z)\n",
        "            fake_imgs = denorm(fake_imgs).cpu()\n",
        "\n",
        "            # Save images\n",
        "            for i in range(cur):\n",
        "                save_image(fake_imgs[i], os.path.join(output_dir, f\"{saved + i:05d}.png\"))\n",
        "\n",
        "            saved += cur\n",
        "            pbar.update(cur)\n",
        "        pbar.close()\n",
        "\n",
        "    del G\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "\n",
        "def calculate_metrics_for_samples(samples_dir):\n",
        "    \"\"\"Calculate FID and IS for generated samples\"\"\"\n",
        "    print(f\"Calculating metrics for: {samples_dir}\")\n",
        "\n",
        "    try:\n",
        "        from torch_fidelity import calculate_metrics\n",
        "    except:\n",
        "        import subprocess\n",
        "        subprocess.check_call(['pip', 'install', '-q', 'torch-fidelity>=0.3.0'])\n",
        "        from torch_fidelity import calculate_metrics\n",
        "\n",
        "    orig_torch_load = torch.load\n",
        "    def _compat_load(*args, **kwargs):\n",
        "        kwargs.setdefault(\"weights_only\", False)\n",
        "        return orig_torch_load(*args, **kwargs)\n",
        "    torch.load = _compat_load\n",
        "\n",
        "    try:\n",
        "        metrics_fid = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            input2=\"cifar10-train\",\n",
        "            fid=True,\n",
        "            kid=False,\n",
        "            isc=False,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        metrics_is = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            fid=False,\n",
        "            kid=False,\n",
        "            isc=True,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "    finally:\n",
        "        torch.load = orig_torch_load\n",
        "\n",
        "    fid = metrics_fid.get(\"frechet_inception_distance\", None)\n",
        "    is_mean = (metrics_is.get(\"inception_score_mean\") or\n",
        "               metrics_is.get(\"isc_mean\") or\n",
        "               metrics_is.get(\"inception_score\"))\n",
        "    is_std = metrics_is.get(\"inception_score_std\", metrics_is.get(\"isc_std\", None))\n",
        "\n",
        "    return fid, is_mean, is_std\n",
        "\n",
        "\n",
        "def evaluate_all_checkpoints(model_dir, ckpt_pattern, temp_sample_dir, num_samples=5000,\n",
        "                             select_epochs=None):\n",
        "    \"\"\"Evaluate all checkpoints in a directory\"\"\"\n",
        "\n",
        "    ckpt_files = sorted(glob.glob(os.path.join(model_dir, ckpt_pattern)))\n",
        "\n",
        "    if not ckpt_files:\n",
        "        print(f\"❌ No checkpoints found matching pattern: {ckpt_pattern} in {model_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"Found {len(ckpt_files)} checkpoints\")\n",
        "\n",
        "    epochs = []\n",
        "    for f in ckpt_files:\n",
        "        match = re.search(r'epoch[_-](\\d+)', os.path.basename(f))\n",
        "        if match:\n",
        "            epochs.append(int(match.group(1)))\n",
        "\n",
        "    if not epochs:\n",
        "        print(\"❌ Could not extract epoch numbers from checkpoint filenames\")\n",
        "        return None, None, None\n",
        "\n",
        "    sorted_pairs = sorted(zip(epochs, ckpt_files))\n",
        "    epochs, ckpt_files = zip(*sorted_pairs)\n",
        "\n",
        "    if select_epochs is not None:\n",
        "        filtered_pairs = [(e, f) for e, f in zip(epochs, ckpt_files) if e in select_epochs]\n",
        "        if filtered_pairs:\n",
        "            epochs, ckpt_files = zip(*filtered_pairs)\n",
        "            print(f\"Evaluating {len(epochs)} selected checkpoints: {list(epochs)}\")\n",
        "        else:\n",
        "            print(f\"❌ No checkpoints found for selected epochs: {select_epochs}\")\n",
        "            return None, None, None\n",
        "\n",
        "    fids = []\n",
        "    is_means = []\n",
        "    is_stds = []\n",
        "\n",
        "    for epoch, ckpt_path in zip(epochs, ckpt_files):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating Epoch {epoch}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            sample_output_dir = os.path.join(temp_sample_dir, f\"epoch_{epoch}\")\n",
        "            generate_samples_from_gan(ckpt_path, sample_output_dir, num_samples)\n",
        "\n",
        "            fid, is_mean, is_std = calculate_metrics_for_samples(sample_output_dir)\n",
        "\n",
        "            fids.append(fid)\n",
        "            is_means.append(is_mean)\n",
        "            is_stds.append(is_std if is_std is not None else 0)\n",
        "\n",
        "            is_std_str = f\"{is_std:.2f}\" if is_std else \"0.00\"\n",
        "            print(f\"✅ Epoch {epoch}: FID={fid:.2f}, IS={is_mean:.2f}±{is_std_str}\")\n",
        "\n",
        "            import shutil\n",
        "            shutil.rmtree(sample_output_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error evaluating epoch {epoch}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return list(epochs), fids, is_means\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# MAIN EVALUATION\n",
        "# -------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING GAN MODEL CHECKPOINTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "TEMP_SAMPLE_DIR = \"/content/temp_eval_samples_gan\"\n",
        "os.makedirs(TEMP_SAMPLE_DIR, exist_ok=True)\n",
        "\n",
        "# SELECT WHICH EPOCHS TO EVALUATE\n",
        "select_epochs = list(range(10, 101, 10))  # [10, 20, 30, ..., 100]\n",
        "print(f\"Will evaluate epochs: {select_epochs}\")\n",
        "\n",
        "gan_epochs, gan_fids, gan_is = evaluate_all_checkpoints(\n",
        "    GAN_DIR,\n",
        "    GAN_CKPT_PATTERN,\n",
        "    os.path.join(TEMP_SAMPLE_DIR, \"gan\"),\n",
        "    num_samples=5000,\n",
        "    select_epochs=select_epochs\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PLOT RESULTS\n",
        "# -------------------------\n",
        "\n",
        "if gan_epochs is not None and len(gan_epochs) > 0:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(gan_epochs, gan_fids, 'g-o', linewidth=2, markersize=8, label='GAN')\n",
        "    ax1.set_xlabel('Epoch', fontsize=14)\n",
        "    ax1.set_ylabel('FID (lower is better)', fontsize=14)\n",
        "    ax1.set_title('GAN: FID vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=12)\n",
        "\n",
        "    ax2.plot(gan_epochs, gan_is, 'm-o', linewidth=2, markersize=8, label='GAN')\n",
        "    ax2.set_xlabel('Epoch', fontsize=14)\n",
        "    ax2.set_ylabel('Inception Score (higher is better)', fontsize=14)\n",
        "    ax2.set_title('GAN: Inception Score vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(GRAPH_OUTPUT_DIR, 'gan_metrics_vs_epochs.png'), dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n✅ Graph saved to: {GRAPH_OUTPUT_DIR}/gan_metrics_vs_epochs.png\")\n",
        "    plt.show()\n",
        "\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        'Epoch': gan_epochs,\n",
        "        'FID': gan_fids,\n",
        "        'IS_mean': gan_is\n",
        "    })\n",
        "    df.to_csv(os.path.join(GRAPH_OUTPUT_DIR, 'gan_metrics.csv'), index=False)\n",
        "    print(f\"✅ Data saved to: {GRAPH_OUTPUT_DIR}/gan_metrics.csv\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GAN SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    best_fid_idx = np.argmin(gan_fids)\n",
        "    best_is_idx = np.argmax(gan_is)\n",
        "    print(f\"Best FID: {gan_fids[best_fid_idx]:.2f} at epoch {gan_epochs[best_fid_idx]}\")\n",
        "    print(f\"Best IS: {gan_is[best_is_idx]:.2f} at epoch {gan_epochs[best_is_idx]}\")\n",
        "    print(f\"Final FID: {gan_fids[-1]:.2f} at epoch {gan_epochs[-1]}\")\n",
        "    print(f\"Final IS: {gan_is[-1]:.2f} at epoch {gan_epochs[-1]}\")\n",
        "else:\n",
        "    print(\"❌ No checkpoints were successfully evaluated\")\n",
        "\n",
        "print(\"\\n✅ GAN Evaluation complete!\")"
      ],
      "metadata": {
        "id": "xy8lpS9MwEmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# EVALUATE VAE CHECKPOINTS AND PLOT FID/IS vs EPOCHS (FIXED)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import math\n",
        "\n",
        "# Try to mount drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    if not os.path.exists('/content/drive/MyDrive'):\n",
        "        drive.mount('/content/drive')\n",
        "    print(\"✅ Drive mounted\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Drive mount failed or not in Colab: {e}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# PATHS\n",
        "# -------------------------\n",
        "\n",
        "VAE_DIR = \"/content/drive/MyDrive/vae_cifar10_runs\"\n",
        "VAE_CKPT_PATTERN = \"vae_epoch_*.pth\"\n",
        "\n",
        "GRAPH_OUTPUT_DIR = \"/content/drive/MyDrive/model_evaluation_graphs\"\n",
        "os.makedirs(GRAPH_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Checkpoint directory: {VAE_DIR}\")\n",
        "print(f\"Graphs will be saved to: {GRAPH_OUTPUT_DIR}\")\n",
        "\n",
        "if not os.path.exists(VAE_DIR):\n",
        "    print(f\"❌ ERROR: Directory does not exist: {VAE_DIR}\")\n",
        "else:\n",
        "    print(f\"✅ Checkpoint directory found\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# VAE MODEL DEFINITIONS\n",
        "# -------------------------\n",
        "\n",
        "def denorm(x):\n",
        "    return (x.clamp(-1,1) + 1)/2\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    z (B,z) → FC 1024 → view (B,256,2,2) → 4× ConvTranspose2d → (B,3,32,32)\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(z_dim, 256*2*2)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256,128,4,2,1,bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),  nn.BatchNorm2d(64),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64,32,4,2,1,bias=False),   nn.BatchNorm2d(32),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(32,3,4,2,1,bias=False),\n",
        "            nn.Tanh(),  # output in [-1,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.fc(z)\n",
        "        h = h.view(h.size(0), 256, 2, 2)\n",
        "        return self.net(h)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EVALUATION FUNCTIONS\n",
        "# -------------------------\n",
        "\n",
        "def load_decoder_from_checkpoint(ckpt_path, z_dim=256):\n",
        "    \"\"\"Load decoder from VAE checkpoint\"\"\"\n",
        "    print(f\"\\nLoading decoder from: {os.path.basename(ckpt_path)}\")\n",
        "\n",
        "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Get z_dim from checkpoint if available\n",
        "    if 'cfg' in ckpt:\n",
        "        try:\n",
        "            if isinstance(ckpt['cfg'], dict):\n",
        "                z_dim = ckpt['cfg'].get('z_dim', 256)\n",
        "            else:\n",
        "                z_dim = getattr(ckpt['cfg'], 'z_dim', 256)\n",
        "            print(f\"Using z_dim from checkpoint: {z_dim}\")\n",
        "        except:\n",
        "            z_dim = 256\n",
        "            print(f\"Using default z_dim: {z_dim}\")\n",
        "\n",
        "    # Create decoder\n",
        "    decoder = Decoder(z_dim).to(device)\n",
        "\n",
        "    # The checkpoint has 'model' which contains the full VAE\n",
        "    if 'model' in ckpt:\n",
        "        full_vae_state = ckpt['model']\n",
        "        # Extract decoder weights (they start with 'dec.')\n",
        "        decoder_state = {}\n",
        "        for key, value in full_vae_state.items():\n",
        "            if key.startswith('dec.'):\n",
        "                new_key = key.replace('dec.', '')\n",
        "                decoder_state[new_key] = value\n",
        "\n",
        "        if decoder_state:\n",
        "            decoder.load_state_dict(decoder_state)\n",
        "            print(f\"✅ Successfully loaded decoder with {len(decoder_state)} parameters\")\n",
        "        else:\n",
        "            raise ValueError(\"No decoder weights found in checkpoint\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected checkpoint structure. Keys: {ckpt.keys()}\")\n",
        "\n",
        "    decoder.eval()\n",
        "    return decoder, z_dim\n",
        "\n",
        "\n",
        "def generate_samples_from_vae(ckpt_path, output_dir, num_samples=5000):\n",
        "    \"\"\"Generate samples from a VAE checkpoint\"\"\"\n",
        "    print(f\"\\nGenerating samples from: {os.path.basename(ckpt_path)}\")\n",
        "\n",
        "    decoder, z_dim = load_decoder_from_checkpoint(ckpt_path)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    bs = 100\n",
        "    saved = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(total=num_samples, desc=\"Generating\")\n",
        "        while saved < num_samples:\n",
        "            cur = min(bs, num_samples - saved)\n",
        "\n",
        "            # Sample from standard normal distribution\n",
        "            z = torch.randn(cur, z_dim, device=device)\n",
        "\n",
        "            # Generate images\n",
        "            fake_imgs = decoder(z)\n",
        "            fake_imgs = denorm(fake_imgs).cpu()\n",
        "\n",
        "            # Save images\n",
        "            for i in range(cur):\n",
        "                save_image(fake_imgs[i], os.path.join(output_dir, f\"{saved + i:05d}.png\"))\n",
        "\n",
        "            saved += cur\n",
        "            pbar.update(cur)\n",
        "        pbar.close()\n",
        "\n",
        "    del decoder\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "\n",
        "def calculate_metrics_for_samples(samples_dir):\n",
        "    \"\"\"Calculate FID and IS for generated samples\"\"\"\n",
        "    print(f\"Calculating metrics for: {samples_dir}\")\n",
        "\n",
        "    try:\n",
        "        from torch_fidelity import calculate_metrics\n",
        "    except:\n",
        "        import subprocess\n",
        "        subprocess.check_call(['pip', 'install', '-q', 'torch-fidelity>=0.3.0'])\n",
        "        from torch_fidelity import calculate_metrics\n",
        "\n",
        "    orig_torch_load = torch.load\n",
        "    def _compat_load(*args, **kwargs):\n",
        "        kwargs.setdefault(\"weights_only\", False)\n",
        "        return orig_torch_load(*args, **kwargs)\n",
        "    torch.load = _compat_load\n",
        "\n",
        "    try:\n",
        "        metrics_fid = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            input2=\"cifar10-train\",\n",
        "            fid=True,\n",
        "            kid=False,\n",
        "            isc=False,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        metrics_is = calculate_metrics(\n",
        "            input1=samples_dir,\n",
        "            fid=False,\n",
        "            kid=False,\n",
        "            isc=True,\n",
        "            cuda=(device == \"cuda\"),\n",
        "            verbose=False,\n",
        "        )\n",
        "    finally:\n",
        "        torch.load = orig_torch_load\n",
        "\n",
        "    fid = metrics_fid.get(\"frechet_inception_distance\", None)\n",
        "    is_mean = (metrics_is.get(\"inception_score_mean\") or\n",
        "               metrics_is.get(\"isc_mean\") or\n",
        "               metrics_is.get(\"inception_score\"))\n",
        "    is_std = metrics_is.get(\"inception_score_std\", metrics_is.get(\"isc_std\", None))\n",
        "\n",
        "    return fid, is_mean, is_std\n",
        "\n",
        "\n",
        "def evaluate_all_checkpoints(model_dir, ckpt_pattern, temp_sample_dir, num_samples=5000,\n",
        "                             select_epochs=None):\n",
        "    \"\"\"Evaluate all checkpoints in a directory\"\"\"\n",
        "\n",
        "    ckpt_files = sorted(glob.glob(os.path.join(model_dir, ckpt_pattern)))\n",
        "\n",
        "    if not ckpt_files:\n",
        "        print(f\"❌ No checkpoints found matching pattern: {ckpt_pattern} in {model_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(f\"Found {len(ckpt_files)} checkpoints\")\n",
        "\n",
        "    epochs = []\n",
        "    for f in ckpt_files:\n",
        "        match = re.search(r'epoch[_-](\\d+)', os.path.basename(f))\n",
        "        if match:\n",
        "            epochs.append(int(match.group(1)))\n",
        "\n",
        "    if not epochs:\n",
        "        print(\"❌ Could not extract epoch numbers from checkpoint filenames\")\n",
        "        return None, None, None\n",
        "\n",
        "    sorted_pairs = sorted(zip(epochs, ckpt_files))\n",
        "    epochs, ckpt_files = zip(*sorted_pairs)\n",
        "\n",
        "    if select_epochs is not None:\n",
        "        filtered_pairs = [(e, f) for e, f in zip(epochs, ckpt_files) if e in select_epochs]\n",
        "        if filtered_pairs:\n",
        "            epochs, ckpt_files = zip(*filtered_pairs)\n",
        "            print(f\"Evaluating {len(epochs)} selected checkpoints: {list(epochs)}\")\n",
        "        else:\n",
        "            print(f\"❌ No checkpoints found for selected epochs: {select_epochs}\")\n",
        "            return None, None, None\n",
        "\n",
        "    fids = []\n",
        "    is_means = []\n",
        "    is_stds = []\n",
        "\n",
        "    for epoch, ckpt_path in zip(epochs, ckpt_files):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating Epoch {epoch}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            sample_output_dir = os.path.join(temp_sample_dir, f\"epoch_{epoch}\")\n",
        "            generate_samples_from_vae(ckpt_path, sample_output_dir, num_samples)\n",
        "\n",
        "            fid, is_mean, is_std = calculate_metrics_for_samples(sample_output_dir)\n",
        "\n",
        "            fids.append(fid)\n",
        "            is_means.append(is_mean)\n",
        "            is_stds.append(is_std if is_std is not None else 0)\n",
        "\n",
        "            is_std_str = f\"{is_std:.2f}\" if is_std else \"0.00\"\n",
        "            print(f\"✅ Epoch {epoch}: FID={fid:.2f}, IS={is_mean:.2f}±{is_std_str}\")\n",
        "\n",
        "            import shutil\n",
        "            shutil.rmtree(sample_output_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error evaluating epoch {epoch}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return list(epochs), fids, is_means\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# MAIN EVALUATION\n",
        "# -------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING VAE MODEL CHECKPOINTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "TEMP_SAMPLE_DIR = \"/content/temp_eval_samples_vae\"\n",
        "os.makedirs(TEMP_SAMPLE_DIR, exist_ok=True)\n",
        "\n",
        "# SELECT WHICH EPOCHS TO EVALUATE\n",
        "select_epochs = list(range(10, 101, 10))  # [10, 20, 30, ..., 100]\n",
        "print(f\"Will evaluate epochs: {select_epochs}\")\n",
        "\n",
        "vae_epochs, vae_fids, vae_is = evaluate_all_checkpoints(\n",
        "    VAE_DIR,\n",
        "    VAE_CKPT_PATTERN,\n",
        "    os.path.join(TEMP_SAMPLE_DIR, \"vae\"),\n",
        "    num_samples=5000,\n",
        "    select_epochs=select_epochs\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PLOT RESULTS\n",
        "# -------------------------\n",
        "\n",
        "if vae_epochs is not None and len(vae_epochs) > 0:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(vae_epochs, vae_fids, 'orange', marker='o', linewidth=2, markersize=8, label='VAE')\n",
        "    ax1.set_xlabel('Epoch', fontsize=14)\n",
        "    ax1.set_ylabel('FID (lower is better)', fontsize=14)\n",
        "    ax1.set_title('VAE: FID vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=12)\n",
        "\n",
        "    ax2.plot(vae_epochs, vae_is, 'brown', marker='o', linewidth=2, markersize=8, label='VAE')\n",
        "    ax2.set_xlabel('Epoch', fontsize=14)\n",
        "    ax2.set_ylabel('Inception Score (higher is better)', fontsize=14)\n",
        "    ax2.set_title('VAE: Inception Score vs Epochs', fontsize=16, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(GRAPH_OUTPUT_DIR, 'vae_metrics_vs_epochs.png'), dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n✅ Graph saved to: {GRAPH_OUTPUT_DIR}/vae_metrics_vs_epochs.png\")\n",
        "    plt.show()\n",
        "\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        'Epoch': vae_epochs,\n",
        "        'FID': vae_fids,\n",
        "        'IS_mean': vae_is\n",
        "    })\n",
        "    df.to_csv(os.path.join(GRAPH_OUTPUT_DIR, 'vae_metrics.csv'), index=False)\n",
        "    print(f\"✅ Data saved to: {GRAPH_OUTPUT_DIR}/vae_metrics.csv\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"VAE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    best_fid_idx = np.argmin(vae_fids)\n",
        "    best_is_idx = np.argmax(vae_is)\n",
        "    print(f\"Best FID: {vae_fids[best_fid_idx]:.2f} at epoch {vae_epochs[best_fid_idx]}\")\n",
        "    print(f\"Best IS: {vae_is[best_is_idx]:.2f} at epoch {vae_epochs[best_is_idx]}\")\n",
        "    print(f\"Final FID: {vae_fids[-1]:.2f} at epoch {vae_epochs[-1]}\")\n",
        "    print(f\"Final IS: {vae_is[-1]:.2f} at epoch {vae_epochs[-1]}\")\n",
        "else:\n",
        "    print(\"❌ No checkpoints were successfully evaluated\")\n",
        "\n",
        "print(\"\\n✅ VAE Evaluation complete!\")"
      ],
      "metadata": {
        "id": "Ne45AYurwKan"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}